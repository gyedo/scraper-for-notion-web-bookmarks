### 신문사 DB에 검색어를 보내고 관련 기사 목록을 Notion에 Web Bookmark 형식으로 받아주는 코드입니다.

Notion 비공식 API인 Notion-Py를 이용했습니다.

---

## 준비 :

1. 노션에 '**스크래핑 전용 페이지**'를 만들어 두어야 합니다. (물론 노션 계정도 있어야 합니다.)
2. 라이브러리 : 노션 비공식 API인 **Notion-py**를 설치해야 합니다. (물론 **BeautifulSoup**도 설치되어 있어야 합니다)
3. **my_notion.py** 파일을 형성해줘야 합니다. 두 줄이면 됩니다. 1행 : token = "내 노션에 들어가 받아온 토큰 값", 2행 : page = "내가 노션에 만들어둔 스크래핑 전용 페이지". 문자열로 적어주시면 됩니다. 개인정보니만큼 비밀로 하셔야 하고요, 특히 토큰 값은 노출되지 않도록 주의하세요. (Notion에서 token값을 얻어오는 방법과 페이지 주소를 얻어오는 방법은 구글 검색으로 확인해보세요.)
4. my_notion.py 파일을 코드가 저장된 곳과 **같은 폴더**에 넣어주세요.
5. 이 코드는 한겨레 아카이브 작업을 위해 만든 코드입니다. 그래서 **한겨레신문사DB**를 읽는 것에 특화되어 있습니다. 다른 언론사의 정보를 이용하시려면 함수 아래 각 변수들을 다르게 지정하셔야 합니다. 원하는 언론사 홈페이지에 들어가 URL을 읽고, 크롬개발자도구를 열어 selector를 확인해주셔야 합니다.


### my_notion.py 파일 만들기
+ my_notion.token = "내 notion의 token값"
+ my_notion.page = "내 notion의 page주소"

(두 줄 작성한 후 파일이름 my_notion.py로 저장)

---

## 용어 :

+ **스크래핑 전용 페이지** : 긁어온 URL들을 Web Bookmark 형식으로 저장할 노션 페이지입니다. 스크래핑용으로 전영 페이지를 만들어놓고, 한번 스크래핑이 끝날 때마다 북마크들을 다른 페이지로 옮겨 비워두면, 코드를 바꾸지 않아도 되어 편리합니다.
+ **목차페이지** : 검색 결과가 나타나는 페이지입니다. 한겨레 신문의 경우 한 페이지에 열다섯개씩 기사 주소가 올라오기 때문에, 여러 개의 페이지가 생성됩니다. 메인함수에서 목차페이지를 나타내는 문자열 변수는 URL이고, 목차페이지들을 모은 리스트 변수는 URLs입니다. 목차페이지의 예는 : <http://m.hani.co.kr/arti/SEARCH/news/date/리원량/list1.html>
+ **기사주소** : 하나의 목차페이지는 그 안에 열다섯개까지 기사주소를 보여줍니다. 메인함수에서 기사주소를 나타내는 문자열 변수는 url이고, 기사주소들을 모은 리스트 변수는 urls입니다. 기사주소의 예는 : <http://m.hani.co.kr/arti/opinion/editorial/928585.html>
+ **기사내용** : 기사주소를 타고 넘어가면 기사내용이 나옵니다. 이 프로그램의 목적은 기사주소만 노션의 스크래핑 전용페이지로 보내는 것이므로, 기사내용은 긁어오지 않습니다. 기사내용이 필요하실 경우, 기사내용을 문자열로 잘 긁어주는 라이브러리로 Newspaper3k를 추천드립니다. 잘 작동할 경우라면 BeautifulSoup보다 간편합니다. (Newspaper 역시 잘 되는 사이트와 잘 안되는 사이트가 있습니다. 한겨레 신문의 경우는 Newspaper로 기사내용이 잘 읽힙니다. 그러나 한겨레21의 기사내용은 잘 읽히지 않습니다.)

---

**주의** : 이 프로그램은 **한겨레신문사DB**를 읽는 것에 특화되어 있습니다. 다른 언론사의 정보를 이용하려면 함수 아래 변수들 몇 가지를 다르게 설정해야 합니다. 언론사 홈페이지에 들어가 주소창과 크롬개발자도구를 확인하며 하나하나 고치는 일은 어렵지는 않지만 약간 귀찮을 수는 있습니다. 사이트 구조상 잘 긁어지지 않는 언론사도 있고, robots.txt로 긁어가지 말아달라고 요청하는 언론사도 있습니다.

---

##실행 :

+ main()함수를 실행시키면 "**키워드**"를 묻는 창이 나옵니다. 복수의 키워드를 넣을 때에는 "%20" 또는 "+" 기호를 넣어 공백없이 연결해주시면 됩니다.
+ 키워드 입력 후 전체 검색수와 전체 페이지수를 보고 너무 적거나 많다 싶으면 중단시키고 처음부터 다시 실행하면 됩니다. 너무 많으면 실행 중 에러가 발생하기도 합니다. (제 작업환경에서는 수백건까지는 잘 돌아갔습니다.)
+ 신문사 서버에서 url을 긁어오는 시간이 오래 걸릴 수 있습니다. 서버에 부담을 주어 디도스 공격 따위로 오인 받지 않기 위해, **일부러 delay를 주기 때문**입니다. 기다리기 불편하시면 **time.sleep(초)** 함수의 입력값을 조정하시면 됩니다.
+ 에러로 작업이 중단되는 것을 피하기 위해 '**예외 처리**'를 코드에 넣었습니다. **이 경우 Web Bookmark가 생성되지 않고 텍스트 블록**으로만 URL이 찍힙니다(아마 잘못된 링크일 가능성이 큽니다.)
+ 그러나 서버나 인터넷의 문제 등 예상하지 못한 상황 때문에 에러가 발생할 수도 있습니다. 이때는 실행을 중단시키고 다시 실행하면 됩니다. 다만 이때, Notion 페이지에 먼저 생성된 주소 목록은 지워지지 않기 때문에 Notion 페이지를 한번 정리한 후 다시 실행시키면 됩니다.
